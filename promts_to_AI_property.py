import os
import json
from pathlib import Path
import google.generativeai as genai
import time
from PyPDF2 import PdfMerger, PdfReader, PdfWriter
from PIL import Image
import concurrent.futures
from datetime import datetime
import re
import threading
import tkinter as tk
from tkinter import filedialog

# --- –ë–õ–û–ö –ê–í–¢–û–†–ò–ó–ê–¶–ò–ò ---
try:
    with open('autorization\\proxy.txt', 'r', encoding='utf-8') as file:
        proxy = file.read().split(":")
        PROXY_ADDRESS, PROXY_PORT, PROXY_LOGIN, PROXY_PASSWORD = proxy
except FileNotFoundError:
    PROXY_ADDRESS = None
    print("‚ö†Ô∏è  –§–∞–π–ª —Å –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –Ω–µ–≥–æ.")

with open('autorization\\API_GEMINI.txt', 'r', encoding='utf-8') as file:
    GOOGLE_API_KEY = file.read()


# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---

def get_decision_date(person_folder):
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞—Ç—É —Ä–µ—à–µ–Ω–∏—è –∏–∑ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è.json."""
    info_file = person_folder / "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è.json"
    if not info_file.exists():
        print("  > –§–∞–π–ª '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è.json' –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –¥–∞—Ç–∞.")
        return "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –¥–∞—Ç—ã"
    try:
        with open(info_file, 'r', encoding='utf-8') as f:
            return json.load(f).get("–î–∞—Ç–∞ —Ä–µ—à–µ–Ω–∏—è", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –¥–∞—Ç—ã")
    except Exception as e:
        print(f"  > –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è.json': {e}")
        return "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –¥–∞—Ç—ã"

def setup_environment():
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ø—Ä–æ–∫—Å–∏ –∏ API-–∫–ª—é—á."""
    try:
        if PROXY_ADDRESS:
            proxy_url = f"http://{PROXY_LOGIN}:{PROXY_PASSWORD}@{PROXY_ADDRESS}:{PROXY_PORT}"
            os.environ['HTTPS_PROXY'] = proxy_url
            os.environ['HTTP_PROXY'] = proxy_url
            print(f"üöÄ –ü—Ä–æ–∫—Å–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {PROXY_ADDRESS}:{PROXY_PORT}")
        genai.configure(api_key=GOOGLE_API_KEY)
        print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Google AI –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ.")
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return False


def find_person_folder():
    """–ù–∞—Ö–æ–¥–∏—Ç –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –≤–Ω—É—Ç—Ä–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ 'People'."""
    people_dir = Path("People")
    if not people_dir.is_dir():
        print(f"‚ùå –û—à–∏–±–∫–∞: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è '{people_dir}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        return None
    subdirectories = [d for d in people_dir.iterdir() if d.is_dir()]
    if len(subdirectories) == 1:
        return subdirectories[0]
    print(f"‚ùå –û—à–∏–±–∫–∞: –í–Ω—É—Ç—Ä–∏ '{people_dir}' –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–æ–≤–Ω–æ –æ–¥–Ω–∞ –ø–∞–ø–∫–∞.")
    return None


def convert_image_to_pdf(image_path, output_pdf_path):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ PDF."""
    try:
        with Image.open(image_path) as img:
            img.convert('RGB').save(output_pdf_path, "PDF", resolution=100.0)
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ {image_path.name}: {e}")
        return False


def upload_file_with_retry(file_path, max_retries=5):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª —Å 5 –ø–æ–ø—ã—Ç–∫–∞–º–∏."""
    for attempt in range(max_retries):
        try:
            print(f"  > –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ '{file_path.name}' (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})...")
            return genai.upload_file(path=file_path)
        except Exception as e:
            print(f"  > ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ '{file_path.name}': {e}")
            if attempt < max_retries - 1:
                time.sleep(2)
    return None


def cleanup_temp_files(files_to_delete):
    """–£–¥–∞–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã."""
    for f in files_to_delete:
        try:
            if f and f.exists():
                f.unlink()
        except OSError:
            pass


# --- –≠–¢–ê–ü 1: –ü–û–î–ì–û–¢–û–í–ö–ê –§–ê–ô–õ–û–í ---

def prepare_analysis_file(person_folder, model):
    """
    1. –î–µ–ª–∏—Ç –í–°–ï –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã –Ω–∞ —á–∞—Å—Ç–∏.
    2. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç "–¥—Ä" —á–∞—Å—Ç–∏, –°–û–ó–î–ê–ï–¢ –ù–û–í–´–ï –§–ê–ô–õ–´ –∏ –£–î–ê–õ–Ø–ï–¢ –°–¢–ê–†–´–ï.
    3. –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–µ + –æ—Å—Ç–∞–ª—å–Ω–æ–µ –≤ –æ–¥–∏–Ω PDF.
    """
    materials_folder = person_folder / "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–µ–ª–∞"
    analysis_folder = person_folder / "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–µ–ª–∞ –ê–Ω–∞–ª–∏–∑"
    analysis_folder.mkdir(exist_ok=True)
    person_name = person_folder.name

    temp_files = []

    # 1. –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–ê–Ø –†–ê–ó–ë–ò–í–ö–ê –í–°–ï–• –§–ê–ô–õ–û–í
    print("\n- –≠—Ç–∞–ø 1/3: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤...")
    all_source_files = list(materials_folder.glob("*.*"))
    file_to_chunks_map = {}  # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–≤—è–∑–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –µ–≥–æ —á–∞—Å—Ç—è–º–∏

    for file_path in all_source_files:
        try:
            if file_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                target_pdf = analysis_folder / f"temp_conv_{file_path.stem}.pdf"
                if not convert_image_to_pdf(file_path, target_pdf): continue
                temp_files.append(target_pdf)
            else:
                target_pdf = file_path

            reader = PdfReader(target_pdf)
            if len(reader.pages) > 50:
                print(f"  > –§–∞–π–ª '{file_path.name}' –±–æ–ª—å—à–æ–π, –¥–µ–ª–∏–º –Ω–∞ —á–∞—Å—Ç–∏...")
                parts = []
                for i, start_page in enumerate(range(0, len(reader.pages), 50)):
                    writer = PdfWriter()
                    end_page = min(start_page + 50, len(reader.pages))
                    for page_num in range(start_page, end_page):
                        writer.add_page(reader.pages[page_num])

                    chunk_path = analysis_folder / f"{target_pdf.stem}_part_{i + 1}.pdf"
                    with open(chunk_path, 'wb') as f_out:
                        writer.write(f_out)
                    parts.append(chunk_path)
                    temp_files.append(chunk_path)
                file_to_chunks_map[file_path] = parts
            else:
                file_to_chunks_map[file_path] = [target_pdf]
        except Exception as e:
            print(f"  > ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª {file_path.name}: {e}")

    # 2. –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø "–î–†" –§–ê–ô–õ–û–í
    print("\n- –≠—Ç–∞–ø 2/3: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏ –∑–∞–º–µ–Ω–∞ '–¥—Ä' —Ñ–∞–π–ª–æ–≤...")
    dr_keywords = ["–¥—Ä", "–¥—Ä—É–≥–∏–µ"]

    # –û—Ç–±–∏—Ä–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ "–¥—Ä" —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    dr_files_to_process = [f for f in all_source_files if any(kw in f.name.lower() for kw in dr_keywords)]
    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã —Å—Ä–∞–∑—É –∏–¥—É—Ç –≤ –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫
    final_pdf_paths = [chunk for f, chunks in file_to_chunks_map.items() if f not in dr_files_to_process for chunk in
                       chunks]

    def process_dr_file_thread(original_dr_file):
        chunks = file_to_chunks_map.get(original_dr_file)
        if not chunks: return

        merged_writer = PdfWriter()

        for chunk_path in chunks:
            uploaded_file = upload_file_with_retry(chunk_path)
            if not uploaded_file: continue
            try:
                prompt = f"""–ê–Ω–∞–ª–∏–∑ PDF. –ù–∞–π–¥–∏ –í–°–ï —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ {person_name}. –í–µ—Ä–Ω–∏ JSON: {{"relevant_pages": [–Ω–æ–º–µ—Ä–∞_—Å—Ç—Ä–∞–Ω–∏—Ü]}}."""
                response = model.generate_content([uploaded_file, prompt], request_options={"timeout": 300})
                if not response.text or not response.text.strip():
                    continue
                result = json.loads(response.text.strip().replace("```json", "").replace("```", ""))
                pages = result.get("relevant_pages", [])

                if pages:
                    reader = PdfReader(chunk_path)
                    for page_num in pages:
                        if 1 <= page_num <= len(reader.pages):
                            merged_writer.add_page(reader.pages[page_num - 1])
            except Exception as e:
                print(f"  > ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —á–∞—Å—Ç–∏ —Ñ–∞–π–ª–∞ '{original_dr_file.name}': {e}")
            finally:
                genai.delete_file(uploaded_file.name)

        if len(merged_writer.pages) > 0:
            # --- –õ–û–ì–ò–ö–ê –ü–ï–†–ï–ò–ú–ï–ù–û–í–ê–ù–ò–Ø –ò –ó–ê–ú–ï–ù–´ ---
            original_stem = original_dr_file.stem
            words = original_stem.split()

            # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 —Å–ª–æ–≤–∞, –µ—Å–ª–∏ –∏—Ö –±–æ–ª—å—à–µ –¥–≤—É—Ö
            if len(words) > 2:
                new_stem = " ".join(words[:-2])
                new_filename = new_stem + original_dr_file.suffix
                new_file_path = materials_folder / new_filename

                print(f"  > –°–æ–∑–¥–∞—é –Ω–æ–≤—ã–π —Ñ–∞–π–ª: '{new_filename}'")
                with open(new_file_path, 'wb') as f_out:
                    merged_writer.write(f_out)

                print(f"  > –£–¥–∞–ª—è—é —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: '{original_dr_file.name}'")
                original_dr_file.unlink()  # –£–¥–∞–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π "–¥—Ä" —Ñ–∞–π–ª

                final_pdf_paths.append(new_file_path)  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
            else:
                # –ï—Å–ª–∏ —Å–ª–æ–≤ –º–∞–ª–æ, –ø—Ä–æ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å, –Ω–æ –≤ –æ—Å–Ω–æ–≤–Ω—É—é –ø–∞–ø–∫—É
                fallback_path = materials_folder / f"extracted_{original_dr_file.name}"
                with open(fallback_path, 'wb') as f_out:
                    merged_writer.write(f_out)
                final_pdf_paths.append(fallback_path)

    if dr_files_to_process:
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            executor.map(process_dr_file_thread, dr_files_to_process)

    # 3. –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –í –ò–¢–û–ì–û–í–´–ô –§–ê–ô–õ
    print("\n- –≠—Ç–∞–ø 3/3: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    if not final_pdf_paths:
        return None, temp_files

    merger = PdfMerger()
    for pdf_path in final_pdf_paths:
        try:
            merger.append(str(pdf_path))
        except Exception as e:
            print(f"  > ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤ —Å–±–æ—Ä–∫—É —Ñ–∞–π–ª {pdf_path.name}: {e}")

    merged_pdf_path = analysis_folder / "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–µ–ª–∞ (–û–±—â–∏–π).pdf"
    merger.write(str(merged_pdf_path))
    merger.close()
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {merged_pdf_path.name}")
    return merged_pdf_path, temp_files


# --- –ó–ê–î–ê–ß–ò –ê–ù–ê–õ–ò–ó–ê ---

def run_property_analysis_task(person_folder, model, merged_pdf_path):
    """–ó–∞–¥–∞—á–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–º—É—â–µ—Å—Ç–≤–∞ —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –≤—ã–≤–æ–¥–∞ –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏."""
    print("\n>> (–ü–æ—Ç–æ–∫ 1) üè† –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –ò–ú–£–©–ï–°–¢–í–ê...")
    uploaded_files_for_property = []
    temp_parts = []

    try:
        # –†–∞–∑–±–∏–≤–∞–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª
        reader = PdfReader(merged_pdf_path)
        for i in range(0, len(reader.pages), 50):
            writer = PdfWriter()
            end_page = min(i + 50, len(reader.pages))
            for page_num in range(i, end_page):
                writer.add_page(reader.pages[page_num])
            part_path = merged_pdf_path.with_name(f"{merged_pdf_path.stem}_analysis_part_{i // 50 + 1}.pdf")
            with open(part_path, 'wb') as part_file:
                writer.write(part_file)
            temp_parts.append(part_path)

        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            results = executor.map(upload_file_with_retry, temp_parts)
            uploaded_files_for_property = [r for r in results if r]

        if not uploaded_files_for_property:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–∞—Å—Ç–∏ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞.")

        # --- –≠–¢–ê–ü–´ 1 –∏ 2 –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ---
        person_name = person_folder.name
        prompt1 = f"""–ù–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö, –Ω–∞–π–¥–∏ –∞–±—Å–æ–ª—é—Ç–Ω–æ –í–°–Å –∏–º—É—â–µ—Å—Ç–≤–æ {person_name}. –ù–µ —É–ø—É—Å—Ç–∏ –Ω–∏—á–µ–≥–æ. –í–µ—Ä–Ω–∏ JSON: {{"all_property": ["–ò–º—É—â–µ—Å—Ç–≤–æ 1"]}}"""
        response1 = model.generate_content(uploaded_files_for_property + [prompt1], request_options={"timeout": 600})
        all_property = json.loads(response1.text.strip().replace("```json", "").replace("```", "")).get("all_property",
                                                                                                        [])

        if not all_property:
            print("  - üè† –ò–º—É—â–µ—Å—Ç–≤–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            return

        prompt2 = f"""–ò–∑ —Å–ø–∏—Å–∫–∞: {json.dumps(all_property, ensure_ascii=False)}, –Ω–∞–π–¥–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –∂–∏–ª—å–µ {person_name}. –í–µ—Ä–Ω–∏ JSON: {{"sole_residence": "–û–ø–∏—Å–∞–Ω–∏–µ –∏–ª–∏ null"}}"""
        response2 = model.generate_content(uploaded_files_for_property + [prompt2], request_options={"timeout": 400})
        sole_residence_data = json.loads(response2.text.strip().replace("```json", "").replace("```", ""))
        with open(person_folder / "–ò–º—É—â–µ—Å—Ç–≤–æ (–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –∂–∏–ª—å–µ).json", "w", encoding="utf-8") as f:
            json.dump(sole_residence_data, f, ensure_ascii=False, indent=4)

        # --- –ù–ê–ß–ê–õ–û –ò–ó–ú–ï–ù–ï–ù–ò–Ø: –≠–¢–ê–ü 3 ---
        property_for_sale = [p for p in all_property if p != sole_residence_data.get("sole_residence")]
        if property_for_sale:
            # 1. –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
            # –Ø –Ω–µ–º–Ω–æ–≥–æ –µ–≥–æ —É–ª—É—á—à–∏–ª, —á—Ç–æ–±—ã –æ–Ω –º–æ–≥ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤, –ø–µ—Ä–µ—á–∏—Å–ª—è—è –∏—Ö —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é.
            prompt3 = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—É–¥—å–±—É —ç—Ç–æ–≥–æ –∏–º—É—â–µ—Å—Ç–≤–∞: {json.dumps(property_for_sale, ensure_ascii=False)}. 
–û–ø—Ä–µ–¥–µ–ª–∏, –±—ã–ª–æ –ª–∏ –æ–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ. 
–í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç –°–¢–†–û–ì–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ –æ–¥–Ω–æ–≥–æ JSON-–æ–±—ä–µ–∫—Ç–∞ —Å –∫–ª—é—á–∞–º–∏ "realized" –∏ "unrealized".
–í –∑–Ω–∞—á–µ–Ω–∏–∏ –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–∞ —É–∫–∞–∂–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Å–∫–æ–ª—å–∫–æ.

–ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞:
{{
    "realized": "–ö–≤–∞—Ä—Ç–∏—Ä–∞ –ø–æ –∞–¥—Ä–µ—Å—É –†–µ—Å–ø—É–±–ª–∏–∫–∞ –ë—É—Ä—è—Ç–∏—è, –≥. –£–ª–∞–Ω-–£–¥—ç, —É–ª. –í–æ–ª–∫–æ–Ω—Å–∫–æ–≥–æ 1–ê",
    "unrealized": "–ê–≤—Ç–æ–º–æ–±–∏–ª—å Lada Vesta, –ó–µ–º–µ–ª—å–Ω—ã–π —É—á–∞—Å—Ç–æ–∫ –ø–æ –∞–¥—Ä–µ—Å—É ..."
}}

–ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞. –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç:
{{
    "realized": "",
    "unrealized": ""
}}
"""
            response3 = model.generate_content(uploaded_files_for_property + [prompt3],
                                               request_options={"timeout": 600})
            sale_data = json.loads(response3.text.strip().replace("```json", "").replace("```", ""))

            # 2. –°–æ–∑–¥–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–≤–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö JSON-—Ñ–∞–π–ª–∞, –∫–∞–∫ –≤—ã –∏ –ø—Ä–æ—Å–∏–ª–∏
            # –§–∞–π–ª –¥–ª—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–º—É—â–µ—Å—Ç–≤–∞
            realized_output = {
                "realized": sale_data.get("realized", "-")
            }
            with open(person_folder / "–ò–º—É—â–µ—Å—Ç–≤–æ (–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ).json", "w", encoding="utf-8") as f:
                json.dump(realized_output, f, ensure_ascii=False, indent=4)

            # –§–∞–π–ª –¥–ª—è –Ω–µ—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–º—É—â–µ—Å—Ç–≤–∞
            unrealized_output = {
                "unrealized": sale_data.get("unrealized", "-")
            }
            with open(person_folder / "–ò–º—É—â–µ—Å—Ç–≤–æ (–ù–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ).json", "w", encoding="utf-8") as f:
                json.dump(unrealized_output, f, ensure_ascii=False, indent=4)

        # --- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø ---

        print("  - ‚úÖ üè† –ê–Ω–∞–ª–∏–∑ –ò–ú–£–©–ï–°–¢–í–ê –∑–∞–≤–µ—Ä—à–µ–Ω.")

    except Exception as e:
        print(f"  - ‚ùå üè† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ò–ú–£–©–ï–°–¢–í–ê: {e}")
    finally:
        cleanup_temp_files(temp_parts)
        for f in uploaded_files_for_property:
            try:
                genai.delete_file(f.name)
            except Exception:
                pass


def run_income_analysis_task(person_folder, model):
    """–ó–∞–¥–∞—á–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ—Ö–æ–¥–æ–≤ —Å —Å–∞–º—ã–º –Ω–∞–¥–µ–∂–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º."""
    print("\n>> (–ü–æ—Ç–æ–∫ 2) üí∞ –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –î–û–•–û–î–û–í...")

    root = tk.Tk()
    root.withdraw()
    root.attributes("-topmost", True)
    file_path_str = filedialog.askopenfilename(title="–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–æ—Ö–æ–¥–∞—Ö (PDF, JPG, PNG)")
    root.destroy()

    if not file_path_str:
        print("  - üí∞ –§–∞–π–ª –¥–ª—è –¥–æ—Ö–æ–¥–æ–≤ –Ω–µ –≤—ã–±—Ä–∞–Ω.")
        return

    income_file_path = Path(file_path_str)
    temp_income_pdf = None
    uploaded_file = None

    try:
        path_to_upload = income_file_path
        if income_file_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:
            print(f"  > –û–±–Ω–∞—Ä—É–∂–µ–Ω —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è '{income_file_path.name}', –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PDF...")
            analysis_folder = person_folder / "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–µ–ª–∞ –ê–Ω–∞–ª–∏–∑"
            analysis_folder.mkdir(exist_ok=True)
            temp_income_pdf = analysis_folder / f"temp_income_conversion_{income_file_path.stem}.pdf"
            if convert_image_to_pdf(income_file_path, temp_income_pdf):
                path_to_upload = temp_income_pdf
                print("  > –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞.")
            else:
                print("  > ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏. –ü–æ–ø—ã—Ç–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")

        uploaded_file = upload_file_with_retry(path_to_upload)
        if not uploaded_file: return

        # --- –ù–ê–ß–ê–õ–û –ò–ó–ú–ï–ù–ï–ù–ò–Ø: –ù–û–í–´–ô –£–°–ò–õ–ï–ù–ù–´–ô –ü–†–û–ú–ü–¢ ---
        success = False
        max_retries = 5
        for attempt in range(max_retries):
            try:
                print(f"  > –ê–Ω–∞–ª–∏–∑ –¥–æ—Ö–æ–¥–æ–≤ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})...")
                person_name = person_folder.name
                decision_date = get_decision_date(person_folder)
                current_date = datetime.now().strftime("%d.%m.%Y")

                # –ù–û–í–´–ô –ü–†–û–ú–ü–¢
                prompt = f"""
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –æ –¥–æ—Ö–æ–¥–∞—Ö (–∑–∞—Ä–ø–ª–∞—Ç–∞ –∏–ª–∏ –ø–µ–Ω—Å–∏—è) –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –≤–µ—Ä–Ω—É—Ç—å –∏—Ö –°–¢–†–û–ì–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è {person_name} –∑–∞ –ø–µ—Ä–∏–æ–¥ —Å {decision_date} –ø–æ {current_date}.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê –í–´–í–û–î–ê:
1. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
2. –ù–ï –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, markdown-—Ä–∞–∑–º–µ—Ç–∫–∏ ```json``` –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞.
3. –ï—Å–ª–∏ –¥–æ—Ö–æ–¥–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π JSON-–æ–±—ä–µ–∫—Ç: {{}}.

–§–û–†–ú–ê–¢ JSON:
{{
  "date_of_receipt": "–¥–∞—Ç—ã —á–µ—Ä–µ–∑ —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π",
  "source_of_receipt": "–∏—Å—Ç–æ—á–Ω–∏–∫–∏ —á–µ—Ä–µ–∑ —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π (—Ç–æ–ª—å–∫–æ '–∑–∞—Ä–ø–ª–∞—Ç–∞' –∏–ª–∏ '–ø–µ–Ω—Å–∏—è')",
  "amount_of_the_receipt": "—Å—É–º–º—ã —á–µ—Ä–µ–∑ —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π",
  "total": "–∏—Ç–æ–≥–æ–≤–∞—è —Å—É–º–º–∞ –≤—Å–µ—Ö –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–π"
}}
"""

                response = model.generate_content([uploaded_file, prompt], request_options={"timeout": 600})

                if not response.text or not response.text.strip():
                    raise ValueError("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API")

                text = response.text.strip().replace("```json", "").replace("```", "")
                income_data = json.loads(text)

                with open(person_folder / "–î–æ—Ö–æ–¥—ã.json", 'w', encoding='utf-8') as f:
                    json.dump(income_data, f, ensure_ascii=False, indent=4)

                print("  - ‚úÖ üí∞ –ê–Ω–∞–ª–∏–∑ –î–û–•–û–î–û–í –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω.")
                success = True
                break

            except (json.JSONDecodeError, ValueError) as e:
                print(f"  - ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ JSON (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
                if 'response' in locals() and hasattr(response, 'text'):
                    print(f"      > –û—Ç–≤–µ—Ç –æ—Ç API –±—ã–ª: '{response.text[:200]}...'")
                if attempt < max_retries - 1:
                    time.sleep(3)

        if not success:
            print("  - ‚ùå üí∞ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å JSON-–æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫.")

    except Exception as e:
        print(f"  - ‚ùå üí∞ –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ—Ö–æ–¥–æ–≤: {e}")
    finally:
        if uploaded_file:
            try:
                genai.delete_file(uploaded_file.name)
            except Exception:
                pass
        if temp_income_pdf:
            cleanup_temp_files([temp_income_pdf])


# --- –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø-–û–†–ö–ï–°–¢–†–ê–¢–û–† ---

def main():
    if not setup_environment(): return
    model = genai.GenerativeModel(model_name="gemini-1.5-pro-latest")
    person_folder = find_person_folder()
    if not person_folder: return

    temp_files_to_clean = []
    try:
        merged_pdf_path, temp_files_to_clean = prepare_analysis_file(person_folder, model)

        print("\n--- –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∑–∞–¥–∞—á –∞–Ω–∞–ª–∏–∑–∞ –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ ---")
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            if merged_pdf_path:
                executor.submit(run_property_analysis_task, person_folder, model, merged_pdf_path)
            else:
                print(">> –ü—Ä–æ–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –∏–º—É—â–µ—Å—Ç–≤–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª.")

            executor.submit(run_income_analysis_task, person_folder, model)

        print("\n--- –í—Å–µ –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≤–µ—Ä—à–µ–Ω—ã ---")

    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ–±—â–∞—è –æ—à–∏–±–∫–∞ –≤ main: {e}")
    finally:
        print("\n- –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞...")
        cleanup_temp_files(temp_files_to_clean)
        print("‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")


if __name__ == "__main__":
    main()